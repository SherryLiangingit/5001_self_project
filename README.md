# 5001_self_project

  The project is about predicting the running time of SGDClassifier in python scikit-learn package. 

  SGDClassifier implements regularized linear models for classification with stochastic gradient descent (SGD) learning. According to the theory of *SGDClassifier*, if the input data set is a matrix of size $(n,p)$, training has a cost of  $O(n\overline{p}k)$ , where $k$ is the number of iterations (epochs) and $\overline{p}$ is the average number of non-zero attributes per sample.
  The synthetic dataset for training is generated using *sklearn.datasets.make_classification*. According to its explaination，‘n_samples’ means the number of samples, ‘n_features’ means the total number of features.
  
## About

  The ipynb file records my work in detail; the py file just runs the main steps; xgboost.csv records my result.
